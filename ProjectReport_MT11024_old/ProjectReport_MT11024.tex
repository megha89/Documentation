%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex

\documentclass[10pt, conference, compsocconf]{IEEEtran}
% \documentclass[conference]{../sty/IEEEtran}


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{Evaluation of OCR Text Correction by\\
	 Crowdsourcing on a Historic Newspaper Archive}

\author{\IEEEauthorblockN{Megha Gupta and Haimonti Dutta*}
\IEEEauthorblockA{Department of Computer Science, IIIT-Delhi\\
**Affiliated to The Center for Computational Learning Systems, Columbia University, New York\\
(megha1124, haimonti)@iiitd.ac.in}
}

% make the title area
\maketitle

\begin{abstract}

Optical Character Recognition (OCR) is a common method of digitizing printed texts so that they can be electronically searched, stored compactly, displayed on-line, and used in text mining applications.\\
The text generated from OCR devices, however, is often garbled due to variations in quality of the input paper, size and style of the font and column layout. This adversely affects retrieval effectiveness and techniques for cleaning the OCR need to be improvised. Often such techniques involve laborious and time consuming manual processing of data.\\
This project deals with a subset of historical newspaper articles in the holdings of the California Digital Newspaper Collection \cite{cdnc} which have been OCR-ed. Patrons of the \cite{cdnc} read the Amador Ledger on a regular basis and correct OCR errors as they come across them.\\
This work can be used to determine whether the OCR text is clean enough to be used for thorough text search. The creation and analysis of this corpus will enable advanced search mechanisms on these holdings making them more
useful to the general public.\\

\end{abstract}

\begin{IEEEkeywords}
OCR; newspapers; historic; crowdsourcing;
\end{IEEEkeywords}

\section{Introduction}
The electronic conversion of scanned images of handwritten or printed text into a machine encoded text is widely done using Optical Character Recognition devices.  It finds most successful applications in the field of machine Learning, Artificial Intelligence and Pattern recognition.\\
OCR deals with the problem of recognising optically generated characters be it offline or online. Its performance directly depends on the quality of input document. The more constrained the input is the better will be the performance of the system. But when it comes to unconstrained handwriting, the performance is far from satisfactory.\\
The main application areas for \cite{OCR} like Automatic number plate readers, form readers, Signature verification and identification fall into three categories that is Data Entry, Text Entry, process automation.\\
This project deals with printed text in the form of Historical Newspaper Articles in the holdings of \cite{cdnc}. One such newspaper, The Amador Ledger published in the early 1900s by the Amador Publishing Company appealed to the community's interests by covering issues unique to gold mining.\\ 
Patrons of the \cite{cdnc} continue to be interested in studying about the status of the local mining industry and consequently read the Amador Ledger on a regular basis even to this day and correct \cite{OCR} errors as they come across them.\\
The corrections made by the patrons generate logfiles that maintain the history of what users have edited which further helps in generating the Corrected OCR corpus for evaluation and analysis.\\
Experiments are performed on both the datasets using the same Query set. The ranked documents retrieved from both the sets are compared using a statistical measure called Spearman's Rank Order Correlation. It measures the strength of association between two ranked variables.\\
This work can be used to determine whether the OCR text is sufficient enough to be used for the thorough text search and analysis and does it meet the user expectation without actually enhancing and enriching the text.\\

\subsection{Project Participants}
This is an individual project.

\subsection{Datasets and Software Used}
\subsubsection{Logfiles}
They were generated using a third party software for user text correction given by Digital Libraries Consulting \cite{digital}.\\
\subsubsection{Raw OCR corpus}
It was extracted from the website \cite{datasource} using Python scripts.\\
\subsubsection{Corrected OCR Corpus}
It was generated by integrating the logfiles and Raw OCR text again using Python scripts.\\
\subsubsection{Query Set}
It was formulated by randomly picking words from Corrected OCR Text using Python scripts.\\
\subsubsection {Software}
PyLucene 3.6.2, a Python extension for accessing Java Apache Lucene was used as an IR software library for enabling full text indexing and searching capabilites.\\


\section{Problem Statement}
This research is primarily focussed on retrieval effectiveness of OCR data versus Corrected data. We are trying to figure out what are the effects of noisy data on text retrieval. To know the difference between the results we need to find a heuristic measure that determines the difference between the retrieval effictiveness of OCR data versus Corrected Data. The aim of the project is to create and analyse the corrected OCR corpus using a metric that would measure the difference between the retrieval effectiveness of both the corpora, that is Raw OCR versus Corrected OCR.

\section{Methodology}
\subsection{Preprocessing \& Data Generation}
\subsubsection{Logfiles} Downloaded the Logfiles from the file server. These Logfiles (xml format) maintain the history of old OCR Text and corresponding corrected text.\\
\subsubsection{Raw OCR Corpus}
These logfile names were decoded into Newspaper name  and Date of Newspaper. \\
For example, Logfile name, AL19000105-changes.log was converted to Amador Ledger, 1900-01-05 \\
Then each of the decoded name was translated into eight individual URLs.\\
http://chroniclingamerica.loc.gov/lccn/sn93052980/1900-01-05/ed-1/seq-1/ocr.txt\\
http://chroniclingamerica.loc.gov/lccn/sn93052980/1900-01-05/ed-1/seq-2/ocr.txt\\
http://chroniclingamerica.loc.gov/lccn/sn93052980/1900-01-05/ed-1/seq-3/ocr.txt\\
http://chroniclingamerica.loc.gov/lccn/sn93052980/1900-01-05/ed-1/seq-4/ocr.txt\\
http://chroniclingamerica.loc.gov/lccn/sn93052980/1900-01-05/ed-1/seq-5/ocr.txt\\
http://chroniclingamerica.loc.gov/lccn/sn93052980/1900-01-05/ed-1/seq-6/ocr.txt\\
http://chroniclingamerica.loc.gov/lccn/sn93052980/1900-01-05/ed-1/seq-7/ocr.txt\\
http://chroniclingamerica.loc.gov/lccn/sn93052980/1900-01-05/ed-1/seq-8/ocr.txt\\
where seq-1 represents the sequence of the pages of the newspaper.
Finally, we downloaded the Raw OCR text from each of these URLs from \cite{datasource} with the help of Python scripts to build the Raw OCR corpus. There are total 190 files in this corpus.\\
\subsubsection{Corrected OCR Corpus}
Replacing the incorrect text with the corrected text from the logfiles in the Raw OCR Corpus, we obtain the Corrected OCR Corpus. Again there are 190 files in this corpus.\\

\subsection{Building IR Model}
PyLucene, is a wrapper around Java Lucene that allows full functionality of  lucene in Python. Its goal is to allow the use of Lucene's text indexing and searching capabilities from Python.\\
We have used PyLucene 3.6.2 in the project for Indexing and retrieving documents. Firstly, inverted indexes were created for both the datasets. An Inverted Index is an inside out arrangement of documents where terms take the center stage and each term points to a list of documents that contain it. Index file  contain fields, that includes, file name, file path and content.\\
Lucene's logical View of Index files features segments which contain indexed documents. Segments can be searched independently and the number of segments are determined by the number of documents to be indexed and the maximum number of documents in each segment.\\
\subsection{Query Set generation}
The Query set was formulated by randomly picking keywords from each of the Corrected OCR document. Each Query comprise of a single word keyword, for example "bapism", "eparmen", "elecors", etc. The number of keywords in the query set is around 200.
\subsection{Experimentation}
The experiments were run on the indexes created on both the datasets using the same query set. Once the query set was generated, it was passed through the searching script that retrieves the documents containing the keywords.\\
 The documents retrieved are ranked according to the frequency of the keyword present in the document. Higher the frequency, higher the ranking order.\\

\subsection{Results}
The ranked retrieved results (documents) from both the corpus for a query "January" are shown below : \\
From Corrected OCR \\

Top 10 matching Documents \\
name:1900-01-12.txt \\
name:1902-01-17.txt \\
name:1900-01-05.txt \\
name:1904-01-08.txt \\
name:1905-01-27.txt \\
name:1902-02-07.txt \\
name:1904-01-29.txt \\
name:1904-12-30.txt \\
name:1905-01-13.txt \\
name:1908-08-14.txt \\

From Raw OCR \\

Top 5 matching Documents \\
name:1900-01-12.txt \\
name:1902-01-17.txt \\
name:1900-01-05.txt \\ 
name:1904-01-08.txt \\
name:1905-01-13.txt \\



\subsection{Evaluation}
The metric we used to compare the ranked retrieved documents is Spearman's rank correlation coefficient(P). It is a nonparametric measure of statistical dependence between two variables. It assesses how well the relationship between two variables can be described using a monotonic function. If there are no repeated data values, a perfect Spearman correlation of +1 or -1 occurs when each of the variables is a perfect monotone function of the other.\\
Spearman's coefficient, like any correlation calculation, is appropriate for both continuous and discrete variables, including ordinal variables.\\
In applications where duplicate values are not present, the spearman's coefficient can be calculated using the below formula.\\
The ranking order of the documents retrieved from the Corrected OCR Corpus ($Y_{i}$) is shown in Rank $y_{i}$ whereas the order for the Raw OCR ($X_{i}$) is given as Rank $x_{i}$ . When the retrieved documents from both the dataset differ, then ranking of the Corrected OCR will be treated as a benchmark and Raw OCR will be ranked according to it. But the actual rank of the Raw OCR will be the sorted order of the rank given in accordance with the benchmark. \\

Differences $d_{i}$ = $x_{i}$ - $y_{i}$  between the ranks of each observation on the two variables are calculated, and P is given by:
P = 1 - $\frac {6\sum d_i^2 }{n(n^2-1)}$ \\

Following table shows the evaluation of P for a single query "January" (Best Case).

\begin{tabular}{ l | c | c | c | r | r }
$Y_{i}$ & $X_{i}$ & Rank $y_{i}$ & Rank $x_{i}$ & $d_{i}$ & $d_{i}^2$ \\
\hline
  12-01-1900 & 12-01-1900 & 1 & 1 & 0 & 0 \\
  17-01-1902 & 17-01-1902 & 2 & 2 & 0 & 0 \\
  05-01-1900 & 05-01-1900 & 3 & 3 & 0 & 0 \\
  08-01-1904 & 08-01-1904 & 4 & 4 & 0 & 0 \\
  27-01-1905 & 13-01-1905 & 5 & 9(5) & 0 & 0 \\
\end{tabular}
\\
\\
${\sum d_i^2}$ = 0 \\
P = 1 - $\frac{6*0}{5*24}$ \\
P = 1 \\

For another Query "Jackson", the evaluation of P (Worst Case) is as follows:

\begin{tabular}{ l | c | c | c | r | r }
 $Y_{i}$ & $X_{i}$ & Rank $y_{i}$ & Rank $x_{i}$ & $d_{i}$ & $d_{i}^2$ \\
\hline
  12-01-1900 & 21-10-1910 & 1 & 10(4) & -3 & 9 \\
  09-12-1910 & 09-12-1910 & 2 & 2(1) & 0 & 0 \\
  08-06-1900 & 23-09-1910 & 3 & 7(2) & 1 & 1 \\
  01-04-1904 & 02-12-1910 & 4 & 8(3) & 1 & 1 \\
  25-05-1900 & 23-12-1910 & 5 & 11(5) & 0 & 0 \\
\end{tabular}
\\
\\
${\sum d_i^2}$ = 11 \\
P = 1 - $\frac{6*11}{5*24}$ \\
P = 0.45 \\

The average value of Spearman's ranked correlation cofficient can be determined by averaging the Best and Worst case. \\
P = $\frac {0.8+0.45}{2}$ = 0.625 \\



\section{Conclusion}
The sign of the Spearman correlation indicates the direction of association between X (Raw OCR results) and Y (Corrected OCR results). If Y tends to increase when X increases, the Spearman correlation coefficient is positive. If Y tends to decrease when X increases, the Spearman correlation coefficient is negative. A Spearman correlation of zero indicates that there is no tendency for Y to either increase or decrease when X increases. The Spearman correlation increases in magnitude as X and Y become closer to being perfect monotone functions of each other. When X and Y are perfectly monotonically related, the Spearman correlation coefficient becomes 1. \\
The average value of Spearman's ranked correlation coefficient calculated by our experiments is 0.625 which can be interpreted as the association between the two corpora is not very strong but the positive value shows that if Raw OCR increases then Corrected OCR will definitely increase.

To use F-measure we need to have the record of relevant documents for each query. Every user has its own notion of relevance as it is a subjective measure.\\



% conference papers do not normally have an appendix
\section{Future Work}
Due to lack of time, we could not incorporate the users feedback or judgement regarding relevant and non relevant documents for particular query. We would like to extend our evaluation using F-score. \\
Also, we would like to enhance our search capabilities from single word query to multiple words or phrases. \\


% use section* for acknowledgement
\section*{Acknowledgment}
I would like to express my gratitude to my Advisor, Dr. Haimonti Dutta for her support, patience and encouragement throughout the course of the project. \\

\nocite{datasource,cdnc,digital}

\section{Bibiliography}
\bibliography{Project_report}
\bibliographystyle{plain}

% that's all folks
\end{document}


